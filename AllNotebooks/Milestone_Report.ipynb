{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Plan\n",
    "### Completed\n",
    "\n",
    "1. Import the Data (B.Walsh)\n",
    "2. Type/Missing Check (B.Walsh)\n",
    "3. Formatted columns to correct DTYpe per Data Dictionary (B.Walsh)\n",
    "4. Dropped rows with missing predictor variables (B.Walsh)\n",
    "    - We dropped dropped 22 rows of data because they were missing variables we needed to calculate our Y values. We canâ€™t impute data that we need to predict our target variables.\n",
    "5. Descriptive Statistics/Histogram Visualization (R.Gill)\n",
    "6. Descriptive stats on all continuous data columns (R.Gill)\n",
    "7. Imputed missing data for rows (B.Walsh/R.Gill/K.Coppinger)\n",
    "    - The only rows with missing data at that point were C3/C7\n",
    "    - We used median to fill missing values because of the huge variance of the data off the mean\n",
    "8. Created a dummy column for our imputed data so we know what rows had their values imputed for C3/C7 (B.Walsh/K.Coppinger)\n",
    "9. Created missing columns for us to use (K.Coppinger)\n",
    "    - Y1, Y2, C3', C5', C6', P(Mid)\n",
    "\n",
    "\n",
    "### Next Steps\n",
    "1. Normalize the data\n",
    "    - Looking to use the z score approach*\n",
    "2. Correlation analysis\n",
    "    - Used to drop heavily correlated columns from our model\n",
    "4. Standardization\n",
    "5. Recoding T1-T5/S1-S3\n",
    "6. Refine variables/test model\n",
    "\n",
    "\n",
    "# Questions\n",
    "\n",
    "1. Error when plotting histograms--okay to ignore?\n",
    "2. Should we normalize our data before we impute the missing values? What about normalizaing before recoding our variables? Does it matter?\n",
    "Take a log first, the range is too huge and it should help out with bringing the range down. Min/Max does not assume normality, but zscore needs to be. 3 standard deviations assumes normaluty, IQR does not. \n",
    "3. For our columns, what should we do with our outliers?\n",
    "    - Some columns have really big outliers (more than 3 std deviations away, the data is not 'normally distributed'). Do we drop these or just let them be? If so, how do we drop rows based on specific values? \n",
    "4. You said that some categorical variables should be binned?\n",
    "    - Is this the text columns (T1-T5)? \n",
    "5. Is the order of our process okay? \n",
    "    - Should we flip some of our steps to make more sense/have a bigger impact on what we are doing?\n",
    "6. What is our 'next step' after all of this?\n",
    "    - We are a little confused on how we actually go and make our dataset for our model. \n",
    "    - Are we looking for variables that are correlated highly to our own Y1 and Y2 variables? \n",
    "    - *will discuss more in meeting with you in person*\n",
    "7. Last night in class you talked about breaking up and ID number in class, as it is not random. Is this applicable to the I3 column (industry?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from meeting\n",
    "\n",
    "We should work out the planning/pipelines and then figure out the modules and pipeplines. Use white boards \n",
    "\n",
    "Make sure we consider the nomraliaty fo our data \n",
    "\n",
    "we can use the 3rd standr deveiation as the valur for the outlieers\n",
    "\n",
    "for I3 for SEC.gov for the industry classification (they group them into 10 categories)\n",
    "\n",
    "we dont have any categorical values, we could covnert from continous, to catgero\n",
    "\n",
    "very last step is feature selection, maybe the right before feature selection we should convert everything into logical\n",
    "\n",
    "two kinds of tradeoffs we may have to do \n",
    "    we may have to pick our favors Y1 or Y2 \n",
    "    he will just rank the seperate metrics seperately \n",
    "    \n",
    "    \n",
    "** get the plan******\n",
    "make a pipeline approach so that we can work in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
