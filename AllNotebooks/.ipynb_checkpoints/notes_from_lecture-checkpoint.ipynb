{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes From Class\n",
    "\n",
    "1) Detect Outliers\n",
    "    - box plot\n",
    "    - historgram\n",
    "    - zscore/std (needs to be normal)\n",
    "    - IQR\n",
    "Outliers are not a 'bad value'. When we try to normalize this or use any of these values, we introduce errors\n",
    "\n",
    "2) Missing Value Imputation\n",
    "    - if the field is continos, we use the mean/median to replace the missing values\n",
    "    - if the field is categroical, we use the mode to replace the missing values\n",
    "\n",
    "3) Data Sampling\n",
    "    - we have to split our data into training and testing \n",
    "        - training: what we use to make our model \n",
    "        - testing: what we use to test our model\n",
    "    - what happens when we have data that is un balanced?\n",
    "        - over/under sampling\n",
    "        - we only do under/over sampling on our test data\n",
    "        1. Undersampling\n",
    "            - when you reduce the value of the oversized colomn to meet the size of the smaller column\n",
    "            - you just cut the values of the larger column to meet the zise of the smaller column so its 50/50\n",
    "            - this limits the performance of our model\n",
    "            - General Rule: use this when the difference is somewhat similar (1.5x is usually fine)\n",
    "        2. Oversampling\n",
    "            - when you duplicate the smaller columns X times to meet the same size of the larger data \n",
    "            - this way introduces a lot of errors into our model \n",
    "            \n",
    "4) Data Scaling (standardization)\n",
    "    - IQR (for non-normal data) [Min-Max sclaing]\n",
    "    - Z-Score (normal data) [z score scaling]\n",
    "    - just move the decimal place\n",
    "\n",
    "5) Encoding\n",
    "    - what we do with our categorical vriables \n",
    "    - don't have to encode birnay values\n",
    "    - more than 3 unqique values, we encode\n",
    "    1. Label Encoding\n",
    "        - If we have Red, Yellow, Blue --> it will be red = 1, yellow = 2, blue = 3\n",
    "    2. One Hot Encoder\n",
    "        - Red, Yellow, Blue --> is_yellow = 0/1, is_blue = 0/1, is_red = 0/1\n",
    "    - scikitlearn has an encoder for us to use if we want to \n",
    "    - always bin then encode\n",
    "    - can ALWAYS bin our continous variable into \n",
    "    - treat binning as an optional step **\n",
    "    - do binning after feature selection **\n",
    "        - see if it makes sense --> we should bin our data models after features have been selected\n",
    "            - only on features after we have selected them\n",
    "6) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
